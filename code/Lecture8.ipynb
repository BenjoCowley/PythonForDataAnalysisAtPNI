{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMD9eAaqJBOgLFGJRXz+XML",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BenjoCowley/PythonForDataAnalysisAtPNI/blob/master/Lecture8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWKpw-UWifUM",
        "colab_type": "text"
      },
      "source": [
        "# Section 1: PCA on two variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSYiRFWhhB0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# generate data\n",
        "if True:\n",
        "    X = np.random.standard_normal(size=(2,200))\n",
        "    X[:,100:] = X[:,100:] + 4*np.ones((2,100))\n",
        "\n",
        "# Step 1: Plot data\n",
        "\n",
        "\n",
        "# Step 2: Apply PCA to get one dimension\n",
        "#   Plot both axes on the 2-d plot\n",
        "\n",
        "\n",
        "# Step 3: Compute explained variance for each variable\n",
        "\n",
        "\n",
        "# Step 4: Plot PC1 in a histogram (hint: use \"hist\")\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be4W8RpUmDBX",
        "colab_type": "text"
      },
      "source": [
        "# Section 2: PCA on many variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKXL7EDQlgrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# generate data\n",
        "if True:\n",
        "    X = []\n",
        "    num_vars = 20\n",
        "    num_clusters = 5\n",
        "    num_samples_per_cluster = 100\n",
        "    for icluster in range(num_clusters):\n",
        "      x_mean = np.random.randint(low=1, high=10, size=(num_vars,)).astype('float')\n",
        "      X_cluster = np.random.normal(size=(num_vars, num_samples_per_cluster), loc=0., scale=1.)\n",
        "      X_cluster = X_cluster + x_mean[:,np.newaxis]\n",
        "      X.append(X_cluster)\n",
        "    X = np.concatenate(X, axis=1)  # transforms list into array\n",
        "\n",
        "# Step 1: Plot variance for each x variable.\n",
        "#   Use a bar plot (hint: use 'np.var' and 'plt.bar')\n",
        "\n",
        "\n",
        "# Step 2: Apply PCA to X\n",
        "\n",
        "\n",
        "# Step 3: Plot variance explained for each dimension.\n",
        "# (use a bar plot)\n",
        "\n",
        "\n",
        "# Step 4: Plot PC1 vs PC2.\n",
        "\n",
        "\n",
        "# Step 5: Plot a heatmap of the loadings\n",
        "#   (hint, use 'plt.imshow')\n"
      ],
      "execution_count": 26,
      "outputs": []
    }
  ]
}
